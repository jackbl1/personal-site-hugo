+++
title="building technology because 'we can' rather than 'we should'"
date="2023-05-06"
summary="thoughts on motivations"
description="thoughts on motivations"
toc=false
readTime=true
autonumber=true
math=true
tags=["AI", "philosophy"]
showTags=false
hideBackToTop=false
+++

I’ve long held the opinion that human specialization is exclusively bad. Specialization is for insects, not humans. When someone tells me _‘oh I don’t do math’_ or _‘computers aren’t for me’_ I have absolutely no patience for them. You are living in a society where math and computers exist, it is your duty to make an effort if you want to participate in this society.

The insidiousness of this specialization becomes clear in cases like Facebook and social media more broadly. We have a bunch of specialized profit-driven developers who realized they could re-design human communication and monetize it. Did they consider whether they should? Did they consider how it would affect the mental health of children? Probably not very much. Specialized profit-driven developers often don’t end up building tools that are very good for the world. They often build tools that make them money.

The insidiousness of specialization will become even more clear in the age of AI. Like social media, and literally every technology before it, a tool with an incredible power for good comes with an equally incredible power for evil. AI can probably propel the world into human flourishing and self-actualization. It can replace mindless jobs and allow humans to live fulfilling, self-actualized lives full of creativity and expression. It can also kill our species. If you think that’s dramatic, I really really implore you to read some of [these](https://www.forbes.com/sites/craigsmith/2023/05/04/geoff-hinton-ais-most-famous-researcher-warns-of-existential-threat/?sh=101c2bde5215) [articles](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/) on AI alignment or [listen](https://www.youtube.com/watch?v=UbruBnv3pZU) to [these](https://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it#t-34273) [talks](https://www.youtube.com/watch?v=3_YX6AgxxYw). We simply don’t know what AI will become capable of, how fast it will acquire capabilities, and which direction it will go.

Trying to align AI is a losing battle. There is a lot of research being done, but it cannot keep up with the pace of AI development. Right now AI is a black box, meaning we don’t know how or why it works.

A better battle to fight would be shifting the incentives of building technology. The root reason that we see all of this technology built, without a second thought about whether it should be built or not, is capitalism. Profit drives innovation. If a technology will earn money, a specialist will build it.

Imagine a world where the incentive is different. A developer isn’t incentivized solely by money. Imagine if a developer were incentivized solely by putting out the most good into the world. When assigning a value to each idea one could work on next, the value equation doesn’t even consider money. A developer simply asks themself, “of these ideas, which one will be the all-encompassing best tool for the world to have?”

This incentive structure no longer leads to specialized profit-driven insect-humans. This incentive structure forces each individual to have a world view in which one must be aware of how the world works and what exists in the world currently. That way one can properly evaluate what would be best for the world. This incentive structure leads to self-actualization.

The question is now how do we create this incentive? I think this will be the most important question for our species in the next 50 years. If there’s a way to circumvent the AI-fueled collapse of society I believe this is the way. Human cooperation has accomplished some incredible things in the past and we now have to accomplish one more.
