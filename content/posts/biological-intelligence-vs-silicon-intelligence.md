+++
title="biological intelligence vs silicon intelligence"
date="2023-07-12"
summary="classifying differences in intelligence"
description="classifying differences in intelligence"
toc=false
readTime=true
autonumber=true
math=true
tags=["AI", "philosophy"]
showTags=false
hideBackToTop=false
+++

It’s really hard to know when to call a thing intelligent because the definition is so subjective. A lot of people would call dolphins intelligent because of the way they communicate and behave as a community. But still it’s a relative term. Saying dolphins are intelligent is like saying buildings are tall. Compared to what?

This issue contributes to our lack of clarity in classifying artificial intelligence. We struggle so much with drawing a comparison because we have never seen intelligence in this form before. In biological intelligence we have data points all along the spectrum. Ants are intelligent compared to amoebas, but not compared to chimpanzees. Humans are intelligent compared to chimpanzees. But are they intelligent compared to ChatGPT? How do we make that comparison?

50 years ago before we accelerated artificial intelligence development and made breakthrough after breakthrough we had a very low bar for AI. If I took a mediocre chess engine and brought it back 50 years ago I have no doubt in my mind the masses would’ve called it intelligent. It can play chess! There are some humans that can’t play chess!

But now we wouldn’t call Stockfish 3 intelligent at all. We have an AI that can write an essay comparing economic theories and pass the bar exam. It is an almost meaningless classifier at this point to call some robots intelligent and others not. It changes so frequently and we only put the bar higher.

We have to build our understanding of silicon intelligence from the ground up. It isn’t unintelligent just because it can’t add 2 numbers, it just has a different form of intelligence. It can’t add 2 numbers but it can program a fully functional calculator in Python in half a second. Silicon intelligence has its strengths and weaknesses but it is certainly an intelligence nonetheless.

A large language model, consisting of billions of parameters in a huge inscrutable matrix, is similar to a baby human brain. In the same way that you can make inferences about a baby’s behavior but you can’t quite reason out all of the actions, you can dig into an LLM’s output but you certainly can’t predict it. Or control it.

Try viewing LLM’s as almost a baby elephant. It has strengths, it has weaknesses, it has its own form of intelligence, it responds to stimuli in patterned but unpredictable ways. Silicon intelligence has very much transcended the simple human-controlled predictable and deterministic programs of the past.
